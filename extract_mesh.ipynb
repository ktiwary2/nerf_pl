{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import mcubes\n",
    "import trimesh\n",
    "\n",
    "# from models.rendering import *\n",
    "from models.rendering_shadows import * # render_rays, efficient_sm\n",
    "\n",
    "\n",
    "from models.nerf import *\n",
    "from dotmap import DotMap\n",
    "\n",
    "from datasets import dataset_dict\n",
    "\n",
    "from utils import load_ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeRF(\n",
       "  (xyz_encoding_1): Sequential(\n",
       "    (0): Linear(in_features=63, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (xyz_encoding_2): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (xyz_encoding_3): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (xyz_encoding_4): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (xyz_encoding_5): Sequential(\n",
       "    (0): Linear(in_features=319, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (xyz_encoding_6): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (xyz_encoding_7): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (xyz_encoding_8): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (xyz_encoding_final): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (dir_encoding): Sequential(\n",
       "    (0): Linear(in_features=283, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (sigma): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (rgb): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=3, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change here #\n",
    "img_wh = (128, 128) # full resolution of the input images\n",
    "dataset_name = 'blender_light_sm' # blender or llff (own data)\n",
    "# ./eff_sm_updated_light_matrix/logs/128x128_single_image_grad_on_sm2_sigma_run3_2gpu/\n",
    "scene_name = 'chairs' # whatever you want\n",
    "# the folder containing data\n",
    "root_dir = '/home/gridsan/ktiwary/datasets/volumetric/results_500_v2_distance_transform_150/' \n",
    "# the model path\n",
    "ckpt_path = './ckpts/128x128_sm2_smapper2d_nimp128_nsamp64_sigma/epoch=461.ckpt'\n",
    "\n",
    "###############\n",
    "hparams = {\n",
    "    'black_and_white_test': False, \n",
    "    'coords_trans': False, \n",
    "    'blur': -1, \n",
    "    'white_pix': -1, \n",
    "}\n",
    "hparams = DotMap(hparams)\n",
    "kwargs = {'root_dir': root_dir,\n",
    "          'img_wh': img_wh, \n",
    "         'hparams': hparams}\n",
    "    \n",
    "chunk = 1024*32\n",
    "# dataset = dataset_dict[dataset_name](**kwargs)\n",
    "\n",
    "embedding_xyz = Embedding(3, 10)\n",
    "embedding_dir = Embedding(3, 4)\n",
    "\n",
    "# nerf_fine = NeRF()\n",
    "nerf_fine = NeRF(in_channels_xyz=6*10+3,\n",
    "                 in_channels_dir=6*4+3)\n",
    "load_ckpt(nerf_fine, ckpt_path, model_name='nerf_fine')\n",
    "nerf_fine.cuda().eval();\n",
    "nerf_fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for tight bounds of the object (trial and error!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32768, 42])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "start (0) + length (63) exceeds dimension size (42).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/state/partition1/slurm_tmp/13599495.0.0/ipykernel_56326/1003623601.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#         xyzdir_embedded = xyz_embedded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyzdir_embedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mout_chunks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnerf_fine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyzdir_embedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mrgbsigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nerfpl_dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/nerf_pl-dev/models/nerf.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, sigma_only)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msigma_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0minput_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dir\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_channels_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_channels_dir\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0minput_xyz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nerfpl_dev/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(tensor, split_size_or_sections, dim)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;31m# split_size_or_sections. The branching code is in _tensor.py, which we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m# call here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size_or_sections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nerfpl_dev/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, split_size, dim)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_with_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_with_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: start (0) + length (63) exceeds dimension size (42)."
     ]
    }
   ],
   "source": [
    "### Tune these parameters until the whole object lies tightly in range with little noise ###\n",
    "N = 128 # controls the resolution, set this number small here because we're only finding\n",
    "        # good ranges here, not yet for mesh reconstruction; we can set this number high\n",
    "        # when it comes to final reconstruction.\n",
    "min_ = -1.2\n",
    "max_ = 1.2\n",
    "xmin, xmax = min_, max_ # left/right range\n",
    "ymin, ymax = min_, max_ # forward/backward range\n",
    "zmin, zmax = min_, max_ # up/down range\n",
    "## Attention! the ranges MUST have the same length!\n",
    "sigma_threshold = 0. # controls the noise (lower=maybe more noise; higher=some mesh might be missing)\n",
    "############################################################################################\n",
    "\n",
    "x = np.linspace(xmin, xmax, N)\n",
    "y = np.linspace(ymin, ymax, N)\n",
    "z = np.linspace(zmin, zmax, N)\n",
    "\n",
    "xyz_ = torch.FloatTensor(np.stack(np.meshgrid(x, y, z), -1).reshape(-1, 3)).cuda()\n",
    "dir_ = torch.zeros_like(xyz_).cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    B = xyz_.shape[0]\n",
    "    out_chunks = []\n",
    "    for i in range(0, B, chunk):\n",
    "        xyz_embedded = embedding_xyz(xyz_[i:i+chunk]) # (N, embed_xyz_channels)\n",
    "        dir_embedded = embedding_dir(dir_[i:i+chunk]) # (N, embed_dir_channels)\n",
    "        xyzdir_embedded = torch.cat([xyz_embedded, dir_embedded], 1)\n",
    "#         xyzdir_embedded = xyz_embedded \n",
    "        print(xyzdir_embedded.shape)\n",
    "        out_chunks += [nerf_fine(xyzdir_embedded)]\n",
    "    rgbsigma = torch.cat(out_chunks, 0)\n",
    "    \n",
    "sigma = rgbsigma[:, -1].cpu().numpy()\n",
    "sigma = np.maximum(sigma, 0)\n",
    "sigma = sigma.reshape(N, N, N)\n",
    "\n",
    "# The below lines are for visualization, COMMENT OUT once you find the best range and increase N!\n",
    "vertices, triangles = mcubes.marching_cubes(sigma, sigma_threshold)\n",
    "mesh = trimesh.Trimesh(vertices/N, triangles)\n",
    "mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You can already export \"colorless\" mesh if you don't need color\n",
    "# mcubes.export_mesh(vertices, triangles, f\"{scene_name}.dae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate .vol file for volume rendering in Unity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert N==512, \\\n",
    "    'Please set N to 512 in the two above cell! Remember to comment out the visualization code (last 3 lines)!'\n",
    "\n",
    "a = 1-np.exp(-(xmax-xmin)/N*sigma)\n",
    "a = a.flatten()\n",
    "rgb = (rgbsigma[:, :3].numpy()*255).astype(np.uint32)\n",
    "i = np.where(a>0)[0] # valid indices (alpha>0)\n",
    "\n",
    "rgb = rgb[i]\n",
    "a = a[i]\n",
    "s = rgb.dot(np.array([1<<24, 1<<16, 1<<8])) + (a*255).astype(np.uint32)\n",
    "res = np.stack([i, s], -1).astype(np.uint32).flatten()\n",
    "with open(f'{scene_name}.vol', 'wb') as f:\n",
    "    f.write(res.tobytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract colored mesh\n",
    "\n",
    "Once you find the best range, now **RESTART** the notebook, and copy the configs to the following cell\n",
    "and execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the variables you have above here! ####\n",
    "img_wh = (800, 800) # full resolution of the input images\n",
    "dataset_name = 'blender' # blender or llff (own data)\n",
    "scene_name = 'lego' # whatever you want\n",
    "root_dir = '/home/ubuntu/data/nerf_example_data/nerf_synthetic/lego/' # the folder containing data\n",
    "ckpt_path = 'ckpts/exp2/epoch=05.ckpt' # the model path\n",
    "\n",
    "N = 128 # controls the resolution, set this number small here because we're only finding\n",
    "        # good ranges here, not yet for mesh reconstruction; we can set this number high\n",
    "        # when it comes to final reconstruction.\n",
    "xmin, xmax = -1.2, 1.2 # left/right range\n",
    "ymin, ymax = -1.2, 1.2 # forward/backward range\n",
    "zmin, zmax = -1.2, 1.2 # up/down range\n",
    "sigma_threshold = 50. # controls the noise (lower=maybe more noise; higher=some mesh might be missing)\n",
    "###############################################\n",
    "\n",
    "import os\n",
    "os.environ['ROOT_DIR'] = root_dir\n",
    "os.environ['DATASET_NAME'] = dataset_name\n",
    "os.environ['SCENE_NAME'] = scene_name\n",
    "os.environ['IMG_SIZE'] = f\"{img_wh[0]} {img_wh[1]}\"\n",
    "os.environ['CKPT_PATH'] = ckpt_path\n",
    "os.environ['N_GRID'] = \"256\" # final resolution. You can set this number high to preserve more details\n",
    "os.environ['X_RANGE'] = f\"{xmin} {xmax}\"\n",
    "os.environ['Y_RANGE'] = f\"{ymin} {ymax}\"\n",
    "os.environ['Z_RANGE'] = f\"{zmin} {zmax}\"\n",
    "os.environ['SIGMA_THRESHOLD'] = str(sigma_threshold)\n",
    "os.environ['OCC_THRESHOLD'] = \"0.2\" # probably doesn't require tuning. If you find the color is not close\n",
    "                                    # to real, try to set this number smaller (the effect of this number\n",
    "                                    # is explained in my youtube video)\n",
    "\n",
    "!python extract_color_mesh.py \\\n",
    "    --root_dir $ROOT_DIR \\\n",
    "    --dataset_name $DATASET_NAME \\\n",
    "    --scene_name $SCENE_NAME \\\n",
    "    --img_wh $IMG_SIZE \\\n",
    "    --ckpt_path $CKPT_PATH \\\n",
    "    --N_grid $N_GRID \\\n",
    "    --x_range $X_RANGE \\\n",
    "    --y_range $Y_RANGE \\\n",
    "    --z_range $Z_RANGE \\\n",
    "    --sigma_threshold $SIGMA_THRESHOLD \\\n",
    "    --occ_threshold $OCC_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-nerfpl_dev]",
   "language": "python",
   "name": "conda-env-.conda-nerfpl_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
